{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries needed\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hor_disc = pd.read_excel(\"Data/DiscreteMotion_Data_Horizontalsetup.xlsx\", sheet_name = \"Sheet1\")\n",
    "# data_hor_cont = pd.read_excel(\"Data/ContinuousMotion_Data_Horizontalsetup.xlsx\", sheet_name = \"Sheet1\")\n",
    "# data_ver_disc = pd.read_excel(\"Data/DiscreteMotion_Data_Verticalsetup.xlsx\", sheet_name = \"Tabelle1\")\n",
    "# data_ver_cont = pd.read_excel(\"Data/ContinuousMotion_Data_Verticalsetup.xlsx\", sheet_name = \"Tabelle1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pow_100</th>\n",
       "      <th>Pow_200</th>\n",
       "      <th>Pow_300</th>\n",
       "      <th>Pow_400</th>\n",
       "      <th>Pow_500</th>\n",
       "      <th>Pow_600</th>\n",
       "      <th>Pow_700</th>\n",
       "      <th>Pow_800</th>\n",
       "      <th>Pow_900</th>\n",
       "      <th>Pow_1000</th>\n",
       "      <th>Pow_1100</th>\n",
       "      <th>Pow_1200</th>\n",
       "      <th>Pow_1300</th>\n",
       "      <th>Pow_1400</th>\n",
       "      <th>Pow_1500</th>\n",
       "      <th>Pow_1600</th>\n",
       "      <th>Pow_1700</th>\n",
       "      <th>Pow_1800</th>\n",
       "      <th>Pow_1900</th>\n",
       "      <th>Pow_2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.009</td>\n",
       "      <td>0.516</td>\n",
       "      <td>5.616</td>\n",
       "      <td>7.860</td>\n",
       "      <td>9.240</td>\n",
       "      <td>9.974999</td>\n",
       "      <td>10.981999</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>12.059999</td>\n",
       "      <td>7.950</td>\n",
       "      <td>12.599</td>\n",
       "      <td>9.990001</td>\n",
       "      <td>9.555000</td>\n",
       "      <td>19.096001</td>\n",
       "      <td>13.938000</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.009</td>\n",
       "      <td>0.516</td>\n",
       "      <td>5.616</td>\n",
       "      <td>7.860</td>\n",
       "      <td>9.240</td>\n",
       "      <td>9.974999</td>\n",
       "      <td>10.981999</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>12.059999</td>\n",
       "      <td>7.950</td>\n",
       "      <td>12.599</td>\n",
       "      <td>9.990001</td>\n",
       "      <td>9.555000</td>\n",
       "      <td>19.096001</td>\n",
       "      <td>13.938000</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.009</td>\n",
       "      <td>5.676</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.930</td>\n",
       "      <td>9.240</td>\n",
       "      <td>9.974999</td>\n",
       "      <td>9.728000</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>11.834999</td>\n",
       "      <td>7.830</td>\n",
       "      <td>12.599</td>\n",
       "      <td>9.990001</td>\n",
       "      <td>10.465000</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>11.039999</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.167</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.199</td>\n",
       "      <td>5.676</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.930</td>\n",
       "      <td>7.854</td>\n",
       "      <td>8.014999</td>\n",
       "      <td>9.728000</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>11.834999</td>\n",
       "      <td>7.830</td>\n",
       "      <td>7.267</td>\n",
       "      <td>9.287000</td>\n",
       "      <td>10.465000</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>11.039999</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.147</td>\n",
       "      <td>2.171</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.199</td>\n",
       "      <td>5.676</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.468</td>\n",
       "      <td>7.854</td>\n",
       "      <td>8.014999</td>\n",
       "      <td>9.472000</td>\n",
       "      <td>10.372999</td>\n",
       "      <td>11.834999</td>\n",
       "      <td>12.267</td>\n",
       "      <td>7.267</td>\n",
       "      <td>9.287000</td>\n",
       "      <td>15.548001</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>11.280000</td>\n",
       "      <td>10.434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pow_100  Pow_200  Pow_300  Pow_400  Pow_500  Pow_600  Pow_700  Pow_800  \\\n",
       "0    0.846    0.044    0.014    0.255    4.009    0.516    5.616    7.860   \n",
       "1    0.846    0.044    0.167    0.255    4.009    0.516    5.616    7.860   \n",
       "2    0.846    0.044    0.167    0.255    4.009    5.676    5.400    6.930   \n",
       "3    0.774    0.147    0.167    4.080    4.199    5.676    5.400    6.930   \n",
       "4    0.774    0.147    2.171    4.080    4.199    5.676    5.400    6.468   \n",
       "\n",
       "   Pow_900  Pow_1000   Pow_1100   Pow_1200   Pow_1300  Pow_1400  Pow_1500  \\\n",
       "0    9.240  9.974999  10.981999   6.578000  12.059999     7.950    12.599   \n",
       "1    9.240  9.974999  10.981999   6.578000  12.059999     7.950    12.599   \n",
       "2    9.240  9.974999   9.728000   6.578000  11.834999     7.830    12.599   \n",
       "3    7.854  8.014999   9.728000   6.578000  11.834999     7.830     7.267   \n",
       "4    7.854  8.014999   9.472000  10.372999  11.834999    12.267     7.267   \n",
       "\n",
       "   Pow_1600   Pow_1700   Pow_1800   Pow_1900  Pow_2000  \n",
       "0  9.990001   9.555000  19.096001  13.938000     0.202  \n",
       "1  9.990001   9.555000  19.096001  13.938000     0.202  \n",
       "2  9.990001  10.465000  13.454000  11.039999     0.564  \n",
       "3  9.287000  10.465000  13.454000  11.039999     0.564  \n",
       "4  9.287000  15.548001  13.454000  11.280000    10.434  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hor_disc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "power_list = [i for i in data_hor_disc.columns]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# perc=0.7\n",
    "\n",
    "\n",
    "# # Splitting the dataset into train and test --> 70% in length is used for train\n",
    "# df_train=data_hor_disc.head(int(len(data_hor_disc)*perc))\n",
    "# df_test=data_hor_disc.head(int(len(data_hor_disc)*(1-perc)))\n",
    "\n",
    "# scaled_train = scaler.fit_transform(df_train[power_list])\n",
    "# scaled_test = scaler.transform(df_test[power_list])\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# power_list = [i for i in data_hor_disc.columns]\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "perc=0.7\n",
    "\n",
    "# Splitting the dataset into train and test --> 70% in length is used for train\n",
    "train_size = int(len(data_hor_disc) * perc)\n",
    "test_size = len(data_hor_disc) - train_size\n",
    "df_train = data_hor_disc[0:train_size]\n",
    "df_test = data_hor_disc[train_size:len(data_hor_disc)]\n",
    "\n",
    "scaled_train = scaler.fit_transform(df_train[power_list])\n",
    "scaled_test = scaler.transform(df_test[power_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)): \n",
    "        lag_end = i + look_back\n",
    "        forecast_end = lag_end + forecast_horizon\n",
    "        if forecast_end > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_test_inverse, yhat_inverse):\n",
    "    mse_ = tf.keras.losses.MeanSquaredError()\n",
    "    mae_ = tf.keras.losses.MeanAbsoluteError()\n",
    "    mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    mae = mae_(y_test_inverse,yhat_inverse)\n",
    "    print('mae:', mae)\n",
    "    mse = mse_(y_test_inverse,yhat_inverse)\n",
    "    print('mse:', mse)\n",
    "    mape = mape_(y_test_inverse,yhat_inverse)\n",
    "    print('mape:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30999, 500, 20)\n",
      "(30999, 1, 20)\n",
      "(13001, 500, 20)\n",
      "(13001, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "LOOK_BACK=500\n",
    "FORECAST_RANGE=1\n",
    "\n",
    "## making the look_back according to the main frequency since the data are kindly periodic\n",
    "\n",
    "n_features=len(power_list)\n",
    "\n",
    "X_train, y_train = split_sequence(scaled_train, look_back=LOOK_BACK, forecast_horizon=FORECAST_RANGE)\n",
    "X_test, y_test = split_sequence(scaled_test, look_back=LOOK_BACK, forecast_horizon=FORECAST_RANGE)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(y_test, yhat):\n",
    "    y_test_reshaped = y_test.reshape(-1, y_test.shape[-1])\n",
    "    yhat_reshaped = yhat.reshape(-1, yhat.shape[-1])\n",
    "    yhat_inverse = scaler.inverse_transform(yhat_reshaped)\n",
    "    y_test_inverse = scaler.inverse_transform(y_test_reshaped)\n",
    "    return yhat_inverse, y_test_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "validation = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'improvementsModel/weights-improvement-{epoch:06d}-{val_loss:.6f}.hdf5'\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.005,\n",
    "    patience=10,\n",
    "    mode='min'\n",
    ")\n",
    "rlrop_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, mode='min', patience=3, min_lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/50\n",
      "872/872 [==============================] - 250s 283ms/step - loss: 0.0184 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "872/872 [==============================] - 214s 245ms/step - loss: 0.0082 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "872/872 [==============================] - 195s 224ms/step - loss: 0.0080 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "872/872 [==============================] - 215s 247ms/step - loss: 0.0079 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "872/872 [==============================] - 216s 248ms/step - loss: 0.0078 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "872/872 [==============================] - 7757s 9s/step - loss: 0.0078 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "872/872 [==============================] - 11067s 13s/step - loss: 0.0077 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "872/872 [==============================] - 6374s 7s/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "872/872 [==============================] - 4847s 6s/step - loss: 0.0075 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "872/872 [==============================] - 6262s 7s/step - loss: 0.0074 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "872/872 [==============================] - 178s 204ms/step - loss: 0.0074 - val_loss: 0.0073 - lr: 0.0010\n",
      "mae: tf.Tensor(0.55529433, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.7113503, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(17503296.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Encoder-Decoder Model\n",
    "\n",
    "model_enc_dec = Sequential()\n",
    "model_enc_dec.add(LSTM(100, activation='tanh', input_shape=(LOOK_BACK, n_features)))\n",
    "model_enc_dec.add(RepeatVector(FORECAST_RANGE))\n",
    "model_enc_dec.add(LSTM(100, activation='tanh', return_sequences=True))\n",
    "model_enc_dec.add(TimeDistributed(Dense(n_features)))\n",
    "model_enc_dec.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "plot_model(model=model_enc_dec, show_shapes=True)\n",
    "history = model_enc_dec.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation,callbacks=[early_stopping_callback, checkpoint_callback, rlrop_callback])\n",
    "yhat = model_enc_dec.predict(X_test, verbose=0)\n",
    "yhat_inverse, y_test_inverse = inverse_transform(y_test, yhat)\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN-LSTM Encoder - Decoder Model\n",
    "\n",
    "model_enc_dec_cnn = Sequential()\n",
    "model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=9, activation='tanh', input_shape=(LOOK_BACK, n_features)))\n",
    "model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=11, activation='tanh'))\n",
    "model_enc_dec_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_enc_dec_cnn.add(Flatten())\n",
    "model_enc_dec_cnn.add(RepeatVector(FORECAST_RANGE))\n",
    "model_enc_dec_cnn.add(LSTM(200, activation='tanh', return_sequences=True))\n",
    "model_enc_dec_cnn.add(TimeDistributed(Dense(100, activation='tanh')))\n",
    "model_enc_dec_cnn.add(TimeDistributed(Dense(n_features)))\n",
    "model_enc_dec_cnn.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Output Model\n",
    "\n",
    "input_layer = Input(shape=(LOOK_BACK, n_features)) \n",
    "conv = Conv1D(filters=4, kernel_size=7, activation='tanh')(input_layer)\n",
    "conv = Conv1D(filters=6, kernel_size=11, activation='tanh')(conv)\n",
    "lstm = LSTM(100, return_sequences=True, activation='tanh')(conv)\n",
    "dropout = Dropout(0.2)(lstm)\n",
    "lstm = LSTM(100, activation='tanh')(dropout)\n",
    "dense = Dense(FORECAST_RANGE*n_features, activation='tanh')(lstm)\n",
    "output_layer = Reshape((FORECAST_RANGE,n_features))(dense)\n",
    "model_vector_output = Model([input_layer], [output_layer])\n",
    "model_vector_output.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(LOOK_BACK, n_features)) \n",
    "head_list = []\n",
    "for i in range(0, n_features):\n",
    "    conv_layer_head = Conv1D(filters=4, kernel_size=7, activation='tanh')(input_layer)\n",
    "    conv_layer_head_2 = Conv1D(filters=6, kernel_size=11, activation='tanh')(conv_layer_head)\n",
    "    conv_layer_flatten = Flatten()(conv_layer_head_2)\n",
    "    head_list.append(conv_layer_flatten)\n",
    " \n",
    "concat_cnn = Concatenate(axis=1)(head_list)\n",
    "reshape = Reshape((head_list[0].shape[1], n_features))(concat_cnn)\n",
    "lstm = LSTM(100, activation='tanh')(reshape)\n",
    "repeat = RepeatVector(FORECAST_RANGE)(lstm)\n",
    "lstm_2 = LSTM(100, activation='tanh', return_sequences=True)(repeat)\n",
    "dropout = Dropout(0.2)(lstm_2)\n",
    "dense = Dense(n_features, activation='linear')(dropout)\n",
    "multi_head_cnn_lstm_model = Model(inputs=input_layer, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MAPE')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_inverse_time_step = y_test_inverse.reshape(int(y_test_inverse.shape[0]/FORECAST_RANGE), FORECAST_RANGE, y_test_inverse.shape[-1])\n",
    "yhat_inverse_time_step = yhat_inverse.reshape(int(yhat_inverse.shape[0]/FORECAST_RANGE), FORECAST_RANGE, yhat_inverse.shape[-1])\n",
    "# yhat_inverse_time_step and y_test_inverse_time_step are both same dimension.\n",
    "time_step_list_yhat = [[] for i in range(FORECAST_RANGE)]\n",
    "time_step_list_y_test = [[] for i in range(FORECAST_RANGE)]\n",
    "for i in range(0, yhat_inverse_time_step.shape[0]):\n",
    " for j in range(0, yhat_inverse_time_step.shape[1]):\n",
    "    time_step_list_yhat[j].append(list(yhat_inverse_time_step[i][j]))\n",
    "    time_step_list_y_test[j].append(list(y_test_inverse_time_step[i][j]))\n",
    "yhat_time_step = np.array(time_step_list_yhat)\n",
    "yhat_time_step = yhat_time_step.reshape(yhat_time_step.shape[0], -1)\n",
    "y_test_time_step = np.array(time_step_list_y_test)\n",
    "y_test_time_step = y_test_time_step.reshape(y_test_time_step.shape[0], -1)\n",
    "# plotting\n",
    "mape_list = []\n",
    "for i in range(0, FORECAST_RANGE):\n",
    "    mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    mape = mape_(y_test_time_step[i], yhat_time_step[i])\n",
    "    mape_list.append(mape)\n",
    "plt.plot(range(0, FORECAST_RANGE), mape_list, marker='o')\n",
    "plt.xticks((range(0, FORECAST_RANGE)))\n",
    "plt.xlabel('Forecast Range')\n",
    "plt.ylabel('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 0\n",
      "mae: tf.Tensor(0.02606634, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.0036150473, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(129248.85, shape=(), dtype=float32)\n",
      "-> 1\n",
      "mae: tf.Tensor(0.056916982, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.018425493, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(2931775.2, shape=(), dtype=float32)\n",
      "-> 2\n",
      "mae: tf.Tensor(0.12408623, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.056486003, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(8315156.0, shape=(), dtype=float32)\n",
      "-> 3\n",
      "mae: tf.Tensor(0.12507056, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.11684565, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(5323252.5, shape=(), dtype=float32)\n",
      "-> 4\n",
      "mae: tf.Tensor(0.18794963, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.2127452, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(6624058.0, shape=(), dtype=float32)\n",
      "-> 5\n",
      "mae: tf.Tensor(0.22663476, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.3452912, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(8302579.5, shape=(), dtype=float32)\n",
      "-> 6\n",
      "mae: tf.Tensor(0.29846114, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.51826656, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(8965112.0, shape=(), dtype=float32)\n",
      "-> 7\n",
      "mae: tf.Tensor(0.35164273, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.6665913, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(20998380.0, shape=(), dtype=float32)\n",
      "-> 8\n",
      "mae: tf.Tensor(0.4804459, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.87505305, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(18214516.0, shape=(), dtype=float32)\n",
      "-> 9\n",
      "mae: tf.Tensor(0.5130109, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.084932, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(14260514.0, shape=(), dtype=float32)\n",
      "-> 10\n",
      "mae: tf.Tensor(0.6697799, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.4795233, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(18072782.0, shape=(), dtype=float32)\n",
      "-> 11\n",
      "mae: tf.Tensor(0.68224055, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.7854829, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(29476378.0, shape=(), dtype=float32)\n",
      "-> 12\n",
      "mae: tf.Tensor(0.6631247, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.8306584, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(20136304.0, shape=(), dtype=float32)\n",
      "-> 13\n",
      "mae: tf.Tensor(0.8257331, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(2.2579026, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(21627434.0, shape=(), dtype=float32)\n",
      "-> 14\n",
      "mae: tf.Tensor(0.8203899, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.1338792, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(28271846.0, shape=(), dtype=float32)\n",
      "-> 15\n",
      "mae: tf.Tensor(1.2005945, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(4.1957254, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(34062350.0, shape=(), dtype=float32)\n",
      "-> 16\n",
      "mae: tf.Tensor(0.86187226, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.2851992, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(19549388.0, shape=(), dtype=float32)\n",
      "-> 17\n",
      "mae: tf.Tensor(0.9876228, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.5910075, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(28193118.0, shape=(), dtype=float32)\n",
      "-> 18\n",
      "mae: tf.Tensor(1.1094679, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(4.681971, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(35135410.0, shape=(), dtype=float32)\n",
      "-> 19\n",
      "mae: tf.Tensor(0.8947762, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(4.087406, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(21476212.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, n_features):\n",
    "    print('->', i)\n",
    "    mse_ = tf.keras.losses.MeanSquaredError()\n",
    "    mae_ = tf.keras.losses.MeanAbsoluteError()\n",
    "    mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    mae = mae_(y_test_inverse[:,i],yhat_inverse[:,i])\n",
    "    print('mae:', mae)\n",
    "    mse = mse_(y_test_inverse[:,i],yhat_inverse[:,i])\n",
    "    print('mse:', mse)\n",
    "    mape = mape_(y_test_inverse[:,i],yhat_inverse[:,i])\n",
    "    print('mape:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
