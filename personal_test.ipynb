{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries needed\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import keras.api._v2.keras as keras\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hor_disc = pd.read_excel(\"Data/DiscreteMotion_Data_Horizontalsetup.xlsx\", sheet_name = \"Sheet1\")\n",
    "# data_hor_cont = pd.read_excel(\"Data/ContinuousMotion_Data_Horizontalsetup.xlsx\", sheet_name = \"Sheet1\")\n",
    "# data_ver_disc = pd.read_excel(\"Data/DiscreteMotion_Data_Verticalsetup.xlsx\", sheet_name = \"Tabelle1\")\n",
    "# data_ver_cont = pd.read_excel(\"Data/ContinuousMotion_Data_Verticalsetup.xlsx\", sheet_name = \"Tabelle1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pow_100</th>\n",
       "      <th>Pow_200</th>\n",
       "      <th>Pow_300</th>\n",
       "      <th>Pow_400</th>\n",
       "      <th>Pow_500</th>\n",
       "      <th>Pow_600</th>\n",
       "      <th>Pow_700</th>\n",
       "      <th>Pow_800</th>\n",
       "      <th>Pow_900</th>\n",
       "      <th>Pow_1000</th>\n",
       "      <th>Pow_1100</th>\n",
       "      <th>Pow_1200</th>\n",
       "      <th>Pow_1300</th>\n",
       "      <th>Pow_1400</th>\n",
       "      <th>Pow_1500</th>\n",
       "      <th>Pow_1600</th>\n",
       "      <th>Pow_1700</th>\n",
       "      <th>Pow_1800</th>\n",
       "      <th>Pow_1900</th>\n",
       "      <th>Pow_2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.009</td>\n",
       "      <td>0.516</td>\n",
       "      <td>5.616</td>\n",
       "      <td>7.860</td>\n",
       "      <td>9.240</td>\n",
       "      <td>9.974999</td>\n",
       "      <td>10.981999</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>12.059999</td>\n",
       "      <td>7.950</td>\n",
       "      <td>12.599</td>\n",
       "      <td>9.990001</td>\n",
       "      <td>9.555000</td>\n",
       "      <td>19.096001</td>\n",
       "      <td>13.938000</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.009</td>\n",
       "      <td>0.516</td>\n",
       "      <td>5.616</td>\n",
       "      <td>7.860</td>\n",
       "      <td>9.240</td>\n",
       "      <td>9.974999</td>\n",
       "      <td>10.981999</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>12.059999</td>\n",
       "      <td>7.950</td>\n",
       "      <td>12.599</td>\n",
       "      <td>9.990001</td>\n",
       "      <td>9.555000</td>\n",
       "      <td>19.096001</td>\n",
       "      <td>13.938000</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.009</td>\n",
       "      <td>5.676</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.930</td>\n",
       "      <td>9.240</td>\n",
       "      <td>9.974999</td>\n",
       "      <td>9.728000</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>11.834999</td>\n",
       "      <td>7.830</td>\n",
       "      <td>12.599</td>\n",
       "      <td>9.990001</td>\n",
       "      <td>10.465000</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>11.039999</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.167</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.199</td>\n",
       "      <td>5.676</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.930</td>\n",
       "      <td>7.854</td>\n",
       "      <td>8.014999</td>\n",
       "      <td>9.728000</td>\n",
       "      <td>6.578000</td>\n",
       "      <td>11.834999</td>\n",
       "      <td>7.830</td>\n",
       "      <td>7.267</td>\n",
       "      <td>9.287000</td>\n",
       "      <td>10.465000</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>11.039999</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.147</td>\n",
       "      <td>2.171</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.199</td>\n",
       "      <td>5.676</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.468</td>\n",
       "      <td>7.854</td>\n",
       "      <td>8.014999</td>\n",
       "      <td>9.472000</td>\n",
       "      <td>10.372999</td>\n",
       "      <td>11.834999</td>\n",
       "      <td>12.267</td>\n",
       "      <td>7.267</td>\n",
       "      <td>9.287000</td>\n",
       "      <td>15.548001</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>11.280000</td>\n",
       "      <td>10.434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pow_100  Pow_200  Pow_300  Pow_400  Pow_500  Pow_600  Pow_700  Pow_800  \\\n",
       "0    0.846    0.044    0.014    0.255    4.009    0.516    5.616    7.860   \n",
       "1    0.846    0.044    0.167    0.255    4.009    0.516    5.616    7.860   \n",
       "2    0.846    0.044    0.167    0.255    4.009    5.676    5.400    6.930   \n",
       "3    0.774    0.147    0.167    4.080    4.199    5.676    5.400    6.930   \n",
       "4    0.774    0.147    2.171    4.080    4.199    5.676    5.400    6.468   \n",
       "\n",
       "   Pow_900  Pow_1000   Pow_1100   Pow_1200   Pow_1300  Pow_1400  Pow_1500  \\\n",
       "0    9.240  9.974999  10.981999   6.578000  12.059999     7.950    12.599   \n",
       "1    9.240  9.974999  10.981999   6.578000  12.059999     7.950    12.599   \n",
       "2    9.240  9.974999   9.728000   6.578000  11.834999     7.830    12.599   \n",
       "3    7.854  8.014999   9.728000   6.578000  11.834999     7.830     7.267   \n",
       "4    7.854  8.014999   9.472000  10.372999  11.834999    12.267     7.267   \n",
       "\n",
       "   Pow_1600   Pow_1700   Pow_1800   Pow_1900  Pow_2000  \n",
       "0  9.990001   9.555000  19.096001  13.938000     0.202  \n",
       "1  9.990001   9.555000  19.096001  13.938000     0.202  \n",
       "2  9.990001  10.465000  13.454000  11.039999     0.564  \n",
       "3  9.287000  10.465000  13.454000  11.039999     0.564  \n",
       "4  9.287000  15.548001  13.454000  11.280000    10.434  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hor_disc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "power_list = [i for i in data_hor_disc.columns]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "perc=0.7\n",
    "\n",
    "\n",
    "# Splitting the dataset into train and test --> 70% in length is used for train\n",
    "df_train=data_hor_disc.head(int(len(data_hor_disc)*perc))\n",
    "df_test=data_hor_disc.head(int(len(data_hor_disc)*(1-perc)))\n",
    "\n",
    "scaled_train = scaler.fit_transform(df_train[power_list])\n",
    "scaled_test = scaler.transform(df_test[power_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, look_back, forecast_horizon):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)): \n",
    "        lag_end = i + look_back\n",
    "        forecast_end = lag_end + forecast_horizon\n",
    "        if forecast_end > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:lag_end], sequence[lag_end:forecast_end]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_test_inverse, yhat_inverse):\n",
    "    mse_ = tf.keras.losses.MeanSquaredError()\n",
    "    mae_ = tf.keras.losses.MeanAbsoluteError()\n",
    "    mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    mae = mae_(y_test_inverse,yhat_inverse)\n",
    "    print('mae:', mae)\n",
    "    mse = mse_(y_test_inverse,yhat_inverse)\n",
    "    print('mse:', mse)\n",
    "    mape = mape_(y_test_inverse,yhat_inverse)\n",
    "    print('mape:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30999, 500, 20)\n",
      "(30999, 1, 20)\n",
      "(13000, 500, 20)\n",
      "(13000, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "LOOK_BACK=500\n",
    "FORECAST_RANGE=1\n",
    "n_features=len(power_list)\n",
    "\n",
    "X_train, y_train = split_sequence(scaled_train, look_back=LOOK_BACK, forecast_horizon=FORECAST_RANGE)\n",
    "X_test, y_test = split_sequence(scaled_test, look_back=LOOK_BACK, forecast_horizon=FORECAST_RANGE)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(y_test, yhat):\n",
    "    y_test_reshaped = y_test.reshape(-1, y_test.shape[-1])\n",
    "    yhat_reshaped = yhat.reshape(-1, yhat.shape[-1])\n",
    "    yhat_inverse = scaler.inverse_transform(yhat_reshaped)\n",
    "    y_test_inverse = scaler.inverse_transform(y_test_reshaped)\n",
    "    return yhat_inverse, y_test_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "validation = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'improvementsModel/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.005,\n",
    "    patience=10,\n",
    "    mode='min'\n",
    ")\n",
    "rlrop_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, mode='min', patience=3, min_lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/50\n",
      "872/872 [==============================] - 190s 214ms/step - loss: 0.0185 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "872/872 [==============================] - 164s 188ms/step - loss: 0.0082 - val_loss: 0.0081 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "872/872 [==============================] - 3002s 3s/step - loss: 0.0080 - val_loss: 0.0078 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "872/872 [==============================] - 2025s 2s/step - loss: 0.0079 - val_loss: 0.0076 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "872/872 [==============================] - 2889s 3s/step - loss: 0.0078 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "872/872 [==============================] - 2087s 2s/step - loss: 0.0077 - val_loss: 0.0075 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "872/872 [==============================] - 2993s 3s/step - loss: 0.0077 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "872/872 [==============================] - 1942s 2s/step - loss: 0.0076 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "872/872 [==============================] - 2842s 3s/step - loss: 0.0075 - val_loss: 0.0074 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "872/872 [==============================] - 2833s 3s/step - loss: 0.0074 - val_loss: 0.0073 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "872/872 [==============================] - 3015s 3s/step - loss: 0.0074 - val_loss: 0.0073 - lr: 0.0010\n",
      "mae: tf.Tensor(0.53602743, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.6878681, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(17027224.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Encoder-Decoder Model\n",
    "\n",
    "model_enc_dec = Sequential()\n",
    "model_enc_dec.add(LSTM(100, activation='tanh', input_shape=(LOOK_BACK, n_features)))\n",
    "model_enc_dec.add(RepeatVector(FORECAST_RANGE))\n",
    "model_enc_dec.add(LSTM(100, activation='tanh', return_sequences=True))\n",
    "model_enc_dec.add(TimeDistributed(Dense(n_features)))\n",
    "model_enc_dec.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "plot_model(model=model_enc_dec, show_shapes=True)\n",
    "history = model_enc_dec.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation,callbacks=[early_stopping_callback, checkpoint_callback, rlrop_callback])\n",
    "yhat = model_enc_dec.predict(X_test, verbose=0)\n",
    "yhat_inverse, y_test_inverse = inverse_transform(y_test, yhat)\n",
    "evaluate_forecast(y_test_inverse, yhat_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN-LSTM Encoder - Decoder Model\n",
    "\n",
    "model_enc_dec_cnn = Sequential()\n",
    "model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=9, activation='tanh', input_shape=(LOOK_BACK, n_features)))\n",
    "model_enc_dec_cnn.add(Conv1D(filters=64, kernel_size=11, activation='tanh'))\n",
    "model_enc_dec_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_enc_dec_cnn.add(Flatten())\n",
    "model_enc_dec_cnn.add(RepeatVector(FORECAST_RANGE))\n",
    "model_enc_dec_cnn.add(LSTM(200, activation='tanh', return_sequences=True))\n",
    "model_enc_dec_cnn.add(TimeDistributed(Dense(100, activation='tanh')))\n",
    "model_enc_dec_cnn.add(TimeDistributed(Dense(n_features)))\n",
    "model_enc_dec_cnn.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Output Model\n",
    "\n",
    "input_layer = Input(shape=(LOOK_BACK, n_features)) \n",
    "conv = Conv1D(filters=4, kernel_size=7, activation='tanh')(input_layer)\n",
    "conv = Conv1D(filters=6, kernel_size=11, activation='tanh')(conv)\n",
    "lstm = LSTM(100, return_sequences=True, activation='tanh')(conv)\n",
    "dropout = Dropout(0.2)(lstm)\n",
    "lstm = LSTM(100, activation='tanh')(dropout)\n",
    "dense = Dense(FORECAST_RANGE*n_features, activation='tanh')(lstm)\n",
    "output_layer = Reshape((FORECAST_RANGE,n_features))(dense)\n",
    "model_vector_output = Model([input_layer], [output_layer])\n",
    "model_vector_output.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(LOOK_BACK, n_features)) \n",
    "head_list = []\n",
    "for i in range(0, n_features):\n",
    "    conv_layer_head = Conv1D(filters=4, kernel_size=7, activation='tanh')(input_layer)\n",
    "    conv_layer_head_2 = Conv1D(filters=6, kernel_size=11, activation='tanh')(conv_layer_head)\n",
    "    conv_layer_flatten = Flatten()(conv_layer_head_2)\n",
    "    head_list.append(conv_layer_flatten)\n",
    " \n",
    "concat_cnn = Concatenate(axis=1)(head_list)\n",
    "reshape = Reshape((head_list[0].shape[1], n_features))(concat_cnn)\n",
    "lstm = LSTM(100, activation='tanh')(reshape)\n",
    "repeat = RepeatVector(FORECAST_RANGE)(lstm)\n",
    "lstm_2 = LSTM(100, activation='tanh', return_sequences=True)(repeat)\n",
    "dropout = Dropout(0.2)(lstm_2)\n",
    "dense = Dense(n_features, activation='linear')(dropout)\n",
    "multi_head_cnn_lstm_model = Model(inputs=input_layer, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MAPE')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_inverse_time_step = y_test_inverse.reshape(int(y_test_inverse.shape[0]/FORECAST_RANGE), FORECAST_RANGE, y_test_inverse.shape[-1])\n",
    "yhat_inverse_time_step = yhat_inverse.reshape(int(yhat_inverse.shape[0]/FORECAST_RANGE), FORECAST_RANGE, yhat_inverse.shape[-1])\n",
    "# yhat_inverse_time_step and y_test_inverse_time_step are both same dimension.\n",
    "time_step_list_yhat = [[] for i in range(FORECAST_RANGE)]\n",
    "time_step_list_y_test = [[] for i in range(FORECAST_RANGE)]\n",
    "for i in range(0, yhat_inverse_time_step.shape[0]):\n",
    " for j in range(0, yhat_inverse_time_step.shape[1]):\n",
    "    time_step_list_yhat[j].append(list(yhat_inverse_time_step[i][j]))\n",
    "    time_step_list_y_test[j].append(list(y_test_inverse_time_step[i][j]))\n",
    "yhat_time_step = np.array(time_step_list_yhat)\n",
    "yhat_time_step = yhat_time_step.reshape(yhat_time_step.shape[0], -1)\n",
    "y_test_time_step = np.array(time_step_list_y_test)\n",
    "y_test_time_step = y_test_time_step.reshape(y_test_time_step.shape[0], -1)\n",
    "# plotting\n",
    "mape_list = []\n",
    "for i in range(0, FORECAST_RANGE):\n",
    "    mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    mape = mape_(y_test_time_step[i], yhat_time_step[i])\n",
    "    mape_list.append(mape)\n",
    "plt.plot(range(0, FORECAST_RANGE), mape_list, marker='o')\n",
    "plt.xticks((range(0, FORECAST_RANGE)))\n",
    "plt.xlabel('Forecast Range')\n",
    "plt.ylabel('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 0\n",
      "mae: tf.Tensor(0.029950965, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.00424189, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(526089.9, shape=(), dtype=float32)\n",
      "-> 1\n",
      "mae: tf.Tensor(0.06918168, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.022993905, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(3379147.8, shape=(), dtype=float32)\n",
      "-> 2\n",
      "mae: tf.Tensor(0.0978364, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.054375585, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(4526972.0, shape=(), dtype=float32)\n",
      "-> 3\n",
      "mae: tf.Tensor(0.13656276, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.118441746, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(5009908.0, shape=(), dtype=float32)\n",
      "-> 4\n",
      "mae: tf.Tensor(0.17824602, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.191793, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(6206362.5, shape=(), dtype=float32)\n",
      "-> 5\n",
      "mae: tf.Tensor(0.23722965, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.33431405, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(12595362.0, shape=(), dtype=float32)\n",
      "-> 6\n",
      "mae: tf.Tensor(0.3338674, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.52531993, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(12979824.0, shape=(), dtype=float32)\n",
      "-> 7\n",
      "mae: tf.Tensor(0.34221065, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.73462397, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(10042602.0, shape=(), dtype=float32)\n",
      "-> 8\n",
      "mae: tf.Tensor(0.40171826, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(0.95110655, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(12694563.0, shape=(), dtype=float32)\n",
      "-> 9\n",
      "mae: tf.Tensor(0.4885359, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.1897237, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(14093634.0, shape=(), dtype=float32)\n",
      "-> 10\n",
      "mae: tf.Tensor(0.5401198, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.4456145, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(17311090.0, shape=(), dtype=float32)\n",
      "-> 11\n",
      "mae: tf.Tensor(0.6388071, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.7325772, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(20042622.0, shape=(), dtype=float32)\n",
      "-> 12\n",
      "mae: tf.Tensor(0.72476184, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(1.9468716, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(30388034.0, shape=(), dtype=float32)\n",
      "-> 13\n",
      "mae: tf.Tensor(0.8044678, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(2.722825, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(23074180.0, shape=(), dtype=float32)\n",
      "-> 14\n",
      "mae: tf.Tensor(0.9268767, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.4419243, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(27548094.0, shape=(), dtype=float32)\n",
      "-> 15\n",
      "mae: tf.Tensor(0.8887775, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.2744, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(24441440.0, shape=(), dtype=float32)\n",
      "-> 16\n",
      "mae: tf.Tensor(0.87999314, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.4520435, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(21181318.0, shape=(), dtype=float32)\n",
      "-> 17\n",
      "mae: tf.Tensor(1.0593958, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.4872518, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(46391280.0, shape=(), dtype=float32)\n",
      "-> 18\n",
      "mae: tf.Tensor(0.99643254, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(3.7109525, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(27645822.0, shape=(), dtype=float32)\n",
      "-> 19\n",
      "mae: tf.Tensor(0.9455772, shape=(), dtype=float32)\n",
      "mse: tf.Tensor(4.4159675, shape=(), dtype=float32)\n",
      "mape: tf.Tensor(20466030.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, n_features):\n",
    "    print('->', i)\n",
    "    mse_ = tf.keras.losses.MeanSquaredError()\n",
    "    mae_ = tf.keras.losses.MeanAbsoluteError()\n",
    "    mape_ = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    mae = mae_(y_test_inverse[:,i],yhat_inverse[:,i])\n",
    "    print('mae:', mae)\n",
    "    mse = mse_(y_test_inverse[:,i],yhat_inverse[:,i])\n",
    "    print('mse:', mse)\n",
    "    mape = mape_(y_test_inverse[:,i],yhat_inverse[:,i])\n",
    "    print('mape:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (v3.10.0:b494f5935c, Oct  4 2021, 14:59:19) [Clang 12.0.5 (clang-1205.0.22.11)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
